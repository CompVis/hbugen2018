<!DOCTYPE HTML>
<!--
  Based on
	Spatial by TEMPLATED
	templated.co @templatedco
	Released for free under the Creative Commons Attribution 3.0 license (templated.co/license)
-->
<html>
	<head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117339330-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-117339330-2');
    </script>
		<title>Towards Learning a Realistic Rendering of Human Behavior</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="landing">

		<!-- Banner -->
			<section id="banner">
        <h2>Towards Learning <br>a Realistic Rendering <br>of Human Behavior</h2>
        <p>
        <a href="https://github.com/pesser">Patrick Esser</a>&ast;, 
        <a href="https://github.com/jhaux">Johannes Haux</a>&ast;,
        <a href="https://hci.iwr.uni-heidelberg.de/tmilbich">Timo Milbich</a>&ast;,
        <a href="https://hci.iwr.uni-heidelberg.de/Staff/bommer">Bj&ouml;rn Ommer</a><br/>
        <a href="https://www.iwr.uni-heidelberg.de/">IWR, Heidelberg University</a><br/>
        <a href="https://eccv2018.org/">ECCV 2018</a> (<a href="http://xavirema.eu/HBUGEN2018/index.html">HBUGEN</a>)</p>
			</section>

			<!-- One -->
				<section id="one" class="wrapper style1">
					<div class="container 75%">
						<div class="row 200%">
							<div class="6u 12u$(medium) vert-center">
                  <div class="container 25%">
                    <div class="image fit captioned align-center">
                      <a href="images/rerender.pdf">
                        <img src="images/paper.jpg" alt="" />
                      </a>
                      <a href="images/rerender.pdf">Paper</a>
                      <div class="headerDivider"></div>
                      <a href="images/rerender.bib">BibTeX</a>
                      <br/>
                      &ast; equal contribution
                    </div>
                  </div>
							</div>
							<div class="6u$ 12u$(medium)">
                <h1>Abstract</h1>
                <p>
        Realistic rendering of human behavior is of great interest for
        applications such as video animations, virtual reality and 
        gaming engines. Commonly animations of persons performing
        actions are rendered by articulating explicit 3D models based on
        sequences of coarse body shape representations simulating a certain
        behavior. While the simulation of natural behavior can be
        efficiently learned, the corresponding 3D
        models are typically designed in manual, laborious processes or
        reconstructed from costly (multi-)sensor data. In this work, we
        present an approach towards a holistic learning framework for
        rendering human behavior in which all components are learned from
        easily available data.
        To enable control over the generated behavior, we utilize motion
        capture data and generate realistic motions based on user
        inputs. Alternatively, we can directly copy behavior from videos and
        learn a rendering of characters using RGB camera data only.
        Our experiments show that we can further
        improve data efficiency by training on multiple characters at the
        same time. Overall our approach shows a new path towards
        easily available, personalized avatar creation.
                </p>
							</div>
						</div>
					</div>
				</section>

			<!-- Two -->
				<section id="two" class="wrapper style2 special">
					<div class="container">
						<header class="major">
							<h2>Results</h2>
							<p>Videos produced by our method</p>
						</header>

            __TEMPLATE_STRING__

          </div>
				</section>


			<!-- Four -->
				<section id="four" class="wrapper style3 special">
					<div class="container">
						<header class="major">
							<h2>Acknowledgement</h2>
              <p>This work has been supported in part by the Heidelberg
              Academy of Science <br/>and a hardware donation from NVIDIA.
              It relies on <a
                                      href="https://compvis.github.io/vunet">VUnet</a>,
                                    <a
                                      href="https://github.com/CMU-Perceptual-Computing-Lab/openpose">OpenPose</a>,
                                    <a
                                      href="https://github.com/tensorflow/models/tree/master/research/deeplab">DeepLab</a>,
                                    <a
                                      href="http://theorangeduck.com/page/phase-functioned-neural-networks-character-control">PFNN</a>,
                                    <br>
                                    and many other Open Source projects.
              The page is based on a design by <a href="http://templated.co">TEMPLATED</a>.</p>
						</header>
					</div>
				</section>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
